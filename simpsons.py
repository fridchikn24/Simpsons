# -*- coding: utf-8 -*-
"""Simpsons.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RKP1o4hgWqsG2ssjmUwJHdrDwJ9HmFxT
"""

!pip install feature_engine
!pip install -U scikit-learn

import sklearn
import feature_engine

# Commented out IPython magic to ensure Python compatibility.
# For DataFrames and manipulations
import pandas as pd
import numpy as np
import scipy.stats as stats

# For data Visualization
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.offline as po
import plotly.graph_objects as go

# %matplotlib inline
import plotly.io as pio
pio.renderers.default = 'colab'

# For splitting the dataset
from sklearn.model_selection import train_test_split

# drop arbitrary features
from sklearn.datasets import fetch_openml

# For categorical variables
from feature_engine.encoding import OneHotEncoder
from feature_engine.encoding import RareLabelEncoder
from feature_engine.encoding import DecisionTreeEncoder
from feature_engine.encoding import MeanEncoder

# For scaling the data
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler

from feature_engine.transformation import YeoJohnsonTransformer
from feature_engine.transformation import LogTransformer

# DIscretization
from sklearn.preprocessing import KBinsDiscretizer

# Handling Outliers
from feature_engine.outliers import Winsorizer

# feature engine wrapper 
from feature_engine.wrappers import SklearnTransformerWrapper

# Using KNN classification for our data
from sklearn.neighbors import KNeighborsClassifier

# creating pipelines 
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer

# Hyper parameter tuning
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import StratifiedKFold

# learning Curves
from sklearn.model_selection import learning_curve

# draws a confusion matrix
from sklearn.metrics import plot_confusion_matrix 
from scipy.stats import uniform, truncnorm, randint, loguniform


# save and load models
import joblib

# Pathlib to navigate file system
from pathlib import Path

from sklearn.neighbors import KNeighborsRegressor



#import os
#os.makedirs("/content/drive/MyDrive/teaching_fall_2021/ml_fall_2021/HW_Assignments/HW6/saved_models")
#!ls

from google.colab import drive
drive.mount('/content/drive/')

save_model_folder = Path("/content/drive/MyDrive/Simpsons/saved_models")
data_folder = Path("/content/drive/MyDrive/Simpsons")

simpsons = data_folder /'simpsons_episodes.csv'
with open(simpsons, encoding="utf8",errors='ignore') as csv_file:
    df = pd.read_csv(csv_file)
df.head()

v = df.isna().sum()
v

golden_age = pd.DataFrame(df['season']<10,dtype='category').replace({True: 1, False: 0})
golden_age

simpsons_vars = df.drop(['original_air_date','id','title','production_code','season','number_in_series','views'],axis=1)
simpsons_vars

from feature_engine.imputation import MeanMedianImputer
imputer = MeanMedianImputer(imputation_method='median', variables= ['us_viewers_in_millions','imdb_rating'])
imputer.fit(simpsons_vars)
simpsons_vars=imputer.transform(simpsons_vars)
x_train, x_test, y_train, y_test = train_test_split(simpsons_vars, golden_age, test_size=0.33, random_state=123,stratify = golden_age)

v = simpsons_vars.isna().sum()
v

SpringField_pipeline = Pipeline([
            #('imputer', MeanMedianImputer(imputation_method='median', variables= 'imdb_rating')),
            #('scalar', SklearnTransformerWrapper(StandardScaler())),
            ('knn_class',KNeighborsClassifier())       
])

param_grid_1 = {
    'knn_class__n_neighbors': range(2,20,2),
    'knn_class__weights': ['uniform', 'distance'],
    'knn_class__p': [1, 2],
    'knn_class__n_jobs':[-1]
}

grid_knn_1 = GridSearchCV(SpringField_pipeline,param_grid_1,cv=5,return_train_score=True)
grid_knn_1.fit(x_train,y_train)

grid_knn_1.best_params_